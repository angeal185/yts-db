[{"title":"Most off in all the wrong directions","rating":23,"date":"23 March 2019","review":"Frankly I recommend that people stick to reading Bostrom, the actual leading expert in the field. He is given relatively short time here and lots of inexpert opinion is given undue weight.\nalso given undue weight is the effect on human behavior, which is a tertiary issue at best.\nNo offense to Richard Linklater, but he comes off as foolish in downplaying the capabilities he actually exemplifies the status quo bias and sounds like someone looking at a non-networked commodore 64 and wondering how \"adding machine\" will ever be powerful.<br><br>The fact is there are a number of high order risk, indeed existential risk problems facing the human race as noted by experts such as Bostrom and Stephen Hawkings. And climate change, gun control, and most other issues are not on that list. The list is: Hostile Artificial Intelligence, singularity (especially malign global governance) , destructive biotechnology or nanotechnology, human genetic engineering, nuclear holocaust, and bioterrorism using genetically modified organisms.","user":"random-70778","rank":[6,11]},{"title":"wtf","rating":1,"date":"11 June 2019","review":"I watched 50 whole minutes of this and then it hit me, this isn't a Rob Zombie documentary.","user":"satania","rank":[2,4]},{"title":"More sensational alarmist than an actual review of the subject.","rating":3,"date":"16 May 2019","review":"Couldn't finish the whole thing but watched most of it. The majority of what I watched was highlighting AI that are built for a specific tasks. Then comparing them to human performance at that specific task.<br><br>Today everyone knows that a computer can go through piles of data faster than a human. The issue is context and subtlety. Anything that breaks the context foreseen by the programmer, breaks the AI.<br><br>Even as amazing as self learning machines are they are only as good as the variables they can evaluate. That's easier to do in a well defined task like chess but is much more difficult in say court cases. It also relies on lots of data with a clear goal. It can't handle one-of situations. It has to build itself up on piles of data.<br><br>From what I saw this documentary pushes the fear of AI becoming better than us and doesn't address just how far we are from a true AI. I would hope to learn more about the roadblocks currently in the field.","user":"johnpechon","rank":[1,2]}]